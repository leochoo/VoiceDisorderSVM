{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the playground for fixing mfcc addition\n",
    "\n",
    "# initialize\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "import glob\n",
    "import parselmouth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# needed for mfcc calculation\n",
    "import statistics\n",
    "import speechpy\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process wav files to get Jitter, Shimmer, HNR, and MFCC\n",
    "\n",
    "def get_voice_data(_path):\n",
    "    # select .wav files only\n",
    "    wav_files = glob.glob(_path + \"/*.wav\")\n",
    "    _type = _path.split(\"/\")[-1] # identify type: my_data, healthy, functional etc...\n",
    "    \n",
    "    # list to hold voice data before turning it into a dataframe\n",
    "    data = []\n",
    "    \n",
    "    # for each audio file,\n",
    "    for wav_file in tqdm(wav_files): # tqdm shows the progress bar\n",
    "        sound = parselmouth.Sound(wav_file) # sound object from wav file\n",
    "        pitch = sound.to_pitch()\n",
    "        pulses = parselmouth.praat.call([sound, pitch], \"To PointProcess (cc)\")\n",
    "\n",
    "        # name analysis\n",
    "        name = os.path.basename(wav_file).split(\".\")[0]  \n",
    "\n",
    "        ## tone\n",
    "        tone = \"\"\n",
    "        if \"l\" in name:\n",
    "            tone = \"l\"\n",
    "        elif \"n\" in name:\n",
    "            tone = \"n\"\n",
    "        elif \"h\" in name:\n",
    "            tone = \"h\"\n",
    "\n",
    "        ## syllable\n",
    "        syllab = \"\"\n",
    "        if \"a\" in name:\n",
    "            syllab = \"a\"\n",
    "        elif \"i\" in name:\n",
    "            syllab = \"i\"\n",
    "        elif \"u\" in name:\n",
    "            syllab = \"u\"\n",
    "\n",
    "        # jitter\n",
    "        jitter = parselmouth.praat.call(pulses, \"Get jitter (local)\", 0.0, 0.0, 0.0001, 0.02, 1.3) * 100\n",
    "\n",
    "        # shimmer\n",
    "        shimmer = parselmouth.praat.call([sound, pulses], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "\n",
    "        # HNR\n",
    "        harmonicity = parselmouth.praat.call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "        hnr = parselmouth.praat.call(harmonicity, \"Get mean\", 0, 0)\n",
    "\n",
    "        # append a bit before adding mfcc\n",
    "        data_row = [name, _type, tone, syllab, jitter, shimmer, hnr]\n",
    "\n",
    "        # MFCC, d1, d2\n",
    "        samplerate, wav_data = wavfile.read(wav_file)\n",
    "        mfccs = speechpy.feature.mfcc(wav_data, samplerate, num_cepstral = 12)\n",
    "        mfccs = mfccs.T # transform to handle wav_data easily \n",
    "        derivatives = speechpy.feature.extract_derivative_feature(mfccs) # this now looks like: [c#][frame#][[mfcc, d1, d2]]\n",
    "\n",
    "        mfcc_list = []\n",
    "        mfcc_d1 = []\n",
    "        mfcc_d2 = []\n",
    "\n",
    "        # for each coefficient,\n",
    "        for i in range(0, len(derivatives)):\n",
    "            mfcc_vars = derivatives[i].T # mfcc, d1, d2\n",
    "\n",
    "            # take the average across the entire time frame\n",
    "            mfcc = statistics.mean(mfcc_vars[0])\n",
    "            d1 = statistics.mean(mfcc_vars[1])\n",
    "            d2 = statistics.mean(mfcc_vars[2])\n",
    "\n",
    "            # append to the list\n",
    "            mfcc_list.append(mfcc)\n",
    "            mfcc_d1.append(d1)\n",
    "            mfcc_d2.append(d2)\n",
    "\n",
    "        data_row = data_row + mfcc_list + mfcc_d1 + mfcc_d2\n",
    "\n",
    "        # append to data\n",
    "        data.append(data_row)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_svd(dataset_path):\n",
    "    healthy_df = get_voice_data(dataset_path + \"/healthy\")\n",
    "    functional_df = get_voice_data(dataset_path + \"/pathological/functional\")\n",
    "    hyperfunctional_df = get_voice_data(dataset_path + \"/pathological/hyperfunctional\")\n",
    "    organic_df = get_voice_data(dataset_path + \"/pathological/organic\")\n",
    "    psychogenic_df = get_voice_data(dataset_path + \"/pathological/psychogenic\")\n",
    "\n",
    "    # Combine the results into one dataframe\n",
    "    frames = [healthy_df, functional_df, hyperfunctional_df, organic_df, psychogenic_df]\n",
    "    combined_df = pd.concat(frames)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath for the test and train datasets\n",
    "test_path = \"/Users/leochoo/dev/VoiceDisorderSVM/data/SVD/test_audio\"\n",
    "train_path = \"/Users/leochoo/dev/VoiceDisorderSVM/data/SVD/train_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00,  9.90it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 11.74it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  8.84it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  8.72it/s]\n",
      "100%|██████████| 27/27 [00:02<00:00,  9.91it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6d22ce754ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate voice report for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_report\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7acaee91a776>\u001b[0m in \u001b[0;36manalyze_svd\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Combine the results into one dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhealthy_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperfunctional_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganic_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsychogenic_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 )\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# generate voice report for test dataset\n",
    "test_report = analyze_svd(test_path)\n",
    "test_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate voice report for train dataset\n",
    "train_report = analyze_svd(train_path)\n",
    "train_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data exported\n",
      "Train data exported\n"
     ]
    }
   ],
   "source": [
    "# Save the outputs to the processed data directory\n",
    "test_report.to_csv (\"./data/processed/test_SVD_j_s_hnr_mfcc_with_d1d2.csv\", index = False, header=True)\n",
    "print(\"Test data exported\")\n",
    "train_report.to_csv (\"./data/processed/train_SVD_j_s_hnr_mfcc_withd1d2.csv\", index = False, header=True)\n",
    "print(\"Train data exported\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20201105 \n",
    "# so i recognized the problem with mfcc calculation so I'm re-doing it correctly.\n",
    "\n",
    "# 1105 09:02 now generating new dataset with the correct average mfcc value. no d1 d2 included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1109 08:55 refactoring done and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('3.8.1': pyenv)",
   "language": "python",
   "name": "python38164bit381pyenvc0e1d4fb139e4c8d8bbd1bcf9c4ee977"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
