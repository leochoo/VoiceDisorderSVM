{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leochoo/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mfunctional\u001b[m\u001b[m      \u001b[1m\u001b[36mhyperfunctional\u001b[m\u001b[m \u001b[1m\u001b[36morganic\u001b[m\u001b[m         \u001b[1m\u001b[36mpsychogenic\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "import glob\n",
    "import parselmouth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# filepath for the dataset\n",
    "root = \"/Users/leochoo/dev/GP2-dev/SVD\"\n",
    "# root = \"./testSVD\"\n",
    "\n",
    "my_data_path = root + \"/my_data\"\n",
    "healthy_path = root + \"/healthy\"\n",
    "patho_path = root + \"/pathological\"\n",
    "\n",
    "!ls {patho_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include MFCC data as well\n",
    "\n",
    "def get_voice_data(_path):\n",
    "    # select .wav files only\n",
    "    wav_files = glob.glob(_path + \"/*.wav\")\n",
    "\n",
    "    n_list = []\n",
    "    tone_list = []\n",
    "    syllab_list = []\n",
    "\n",
    "    j_list = []\n",
    "    s_list = []\n",
    "    h_list = []\n",
    "\n",
    "    # for wav_file in wav_files:\n",
    "    for wav_file in tqdm(wav_files): # tqdm shows the progress bar\n",
    "        sound = parselmouth.Sound(wav_file) # sound object from wav file\n",
    "        pitch = sound.to_pitch()\n",
    "        pulses = parselmouth.praat.call([sound, pitch], \"To PointProcess (cc)\")\n",
    "\n",
    "        # name analysis\n",
    "        name = os.path.basename(wav_file).split(\".\")[0]  \n",
    "        \n",
    "        ## tone\n",
    "        if \"l\" in name:\n",
    "            tone_list.append(\"l\")\n",
    "        elif \"n\" in name:\n",
    "            tone_list.append(\"n\")\n",
    "        elif \"h\" in name:\n",
    "            tone_list.append(\"h\")\n",
    "\n",
    "        ## syllable\n",
    "        if \"a\" in name:\n",
    "            syllab_list.append(\"a\")\n",
    "        elif \"i\" in name:\n",
    "            syllab_list.append(\"i\")\n",
    "        elif \"u\" in name:\n",
    "            syllab_list.append(\"u\")\n",
    "        # jitter\n",
    "        jitter_local = parselmouth.praat.call(pulses, \"Get jitter (local)\", 0.0, 0.0, 0.0001, 0.02, 1.3) * 100\n",
    "\n",
    "        # shimmer\n",
    "        shimmer_local = parselmouth.praat.call([sound, pulses], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "\n",
    "        # HNR\n",
    "        harmonicity = parselmouth.praat.call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "        hnr = parselmouth.praat.call(harmonicity, \"Get mean\", 0, 0)\n",
    "        \n",
    "        # Append to numpy array\n",
    "        n_list.append(name)\n",
    "        j_list.append(jitter_local)\n",
    "        s_list.append(shimmer_local)\n",
    "        h_list.append(hnr)\n",
    "\n",
    "        # MFCC\n",
    "        mfcc_object = sound.to_mfcc(number_of_coefficients=13)\n",
    "        mfcc_arr = mfcc_object.to_array()\n",
    "        mfcc_dic = {}\n",
    "        for i in range(1,len(mfcc_arr)):\n",
    "            mfcc_dic[\"MFCC-\"+str(i)] = mfcc_arr[i]\n",
    "        mfcc_df = pd.DataFrame.from_dict(mfcc_dic)\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame({\"Name\":pd.Series(n_list),\n",
    "                        \"Type\": np.nan,\n",
    "                        \"Tone\": pd.Series(tone_list),\n",
    "                        \"Syllab\": pd.Series(syllab_list),\n",
    "                           \"Jitter\":pd.Series(j_list),\n",
    "                           \"Shimmer\":pd.Series(s_list),\n",
    "                           \"HNR\":pd.Series(h_list)})\n",
    "    df[\"Type\"]= _path.split(\"/\")[-1] # identify type: my_data, healthy, functional etc...\n",
    "    new_df = pd.concat([df, mfcc_df], axis=1, sort=False)\n",
    "    new_df = new_df.dropna() # some data are missing jitter, shimmer, hnr for some reason it seems..?\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3141/3141 [03:58<00:00, 13.16it/s]\n",
      "100%|██████████| 1008/1008 [01:13<00:00, 13.70it/s]\n",
      " 22%|██▏       | 418/1916 [00:31<01:53, 13.16it/s]"
     ]
    }
   ],
   "source": [
    "healthy_df = get_voice_data(healthy_path)\n",
    "functional_df = get_voice_data(patho_path + \"/functional\")\n",
    "hyperfunctional_df = get_voice_data(patho_path + \"/hyperfunctional\")\n",
    "organic_df = get_voice_data(patho_path + \"/organic\")\n",
    "psychogenic_df = get_voice_data(patho_path + \"/psychogenic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat(frames)\n",
    "new_df = new_df.dropna()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv (\"./SVD_j_s_hnr_mfcc.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020-07-28 \n",
    "It is mysterious how I'm getting a bunch of NaN when I run the functiosn above. It seems that when i run without MFCC, healthy data is fine but when i run with MFCC it is not okay.\n",
    "\n",
    "I need to look into this. But for today, I will just cut out all the NaN values and proceed with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('3.8.1': pyenv)",
   "language": "python",
   "name": "python38164bit381pyenvc0e1d4fb139e4c8d8bbd1bcf9c4ee977"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
